{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import os\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import subprocess\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "\n",
    "portal_obs_fields = [\n",
    "    'assay',\n",
    "    'cell_type',\n",
    "    'development_stage',\n",
    "    'disease',\n",
    "    'self_reported_ethnicity',\n",
    "    'organism',\n",
    "    'sex',\n",
    "    'tissue'\n",
    "]\n",
    "full_obs_standards = portal_obs_fields + [e + '_ontology_term_id' for e in portal_obs_fields] + ['donor_id','suspension_type','is_primary_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_obs_standards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to load the following libraries. Make sure that the anndata version you have installed matches the one used by [cellxgene-schema](https://github.com/chanzuckerberg/single-cell-curation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show anndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show cellxgene-schema \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the AnnData object\n",
    "**Update the name of the file (without the .h5ad extension)**<br>\n",
    "*The sample `my_matrix.h5ad` that is in this repo is subsampled from https://cellxgene.cziscience.com/e/f15e263b-6544-46cb-a46e-e33ab7ce8347.cxg/ with some metadata alterations for the purpose of this tutorial*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'lung_5loc_sc_sn_cellxgene_23092022'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the AnnData object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(file + '.h5ad')\n",
    "adata.raw.X "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data layers\n",
    "**If needed, transfer to sparse matrix format, this saves space**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count_nonzero = counts the number of non-zero values in the array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_sparsity(x):\n",
    "    if isinstance(x, sparse.coo_matrix) or isinstance(x, sparse.csr_matrix) or isinstance(x, sparse.csc.csc_matrix):\n",
    "        sparsity = 1 - x.count_nonzero() / float(np.cumprod(x.shape)[-1])\n",
    "    elif isinstance(x, np.ndarray):\n",
    "        sparsity = 1 - np.count_nonzero(x) / float(np.cumprod(x.shape)[-1])\n",
    "    else:\n",
    "        print(f'matrix is of type {type(x)}, sparsity calculation has not been implemented')\n",
    "\n",
    "    return sparsity\n",
    "\n",
    "\n",
    "max_sparsity = 0.5\n",
    "\n",
    "sparsity = determine_sparsity(adata.X)\n",
    "print(f'X sparsity: {sparsity}')\n",
    "if sparsity > max_sparsity and type(adata.X) != sparse.csr.csr_matrix:\n",
    "    print('converting X to sparse')\n",
    "    adata.X = sparse.csr_matrix(adata.X)\n",
    "\n",
    "if adata.raw:\n",
    "    sparsity = determine_sparsity(adata.raw.X)\n",
    "    print(f'raw.X sparsity: {sparsity}')\n",
    "    if sparsity > max_sparsity and type(adata.raw.X) != sparse.csr.csr_matrix:\n",
    "        print('converting raw.X to sparse')\n",
    "        raw_adata = ad.AnnData(adata.raw.X, var=adata.raw.var, obs=adata.obs)\n",
    "        raw_adata.X = sparse.csr_matrix(raw_adata.X)\n",
    "        adata.raw = raw_adata\n",
    "        del raw_adata\n",
    "\n",
    "for l in adata.layers:\n",
    "    sparsity = determine_sparsity(adata.layers[l])\n",
    "    print(f'layers[{l}] sparsity: {sparsity}')\n",
    "    if sparsity > max_sparsity and type(adata.layers[l]) != sparse.csr.csr_matrix:\n",
    "        print(f'converting layers[{l}] to sparse')\n",
    "        adata.layers[l] = sparse.csr_matrix(adata.layers[l])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the min/max of each layer**<br>\n",
    "*Look for duplicated or other unnecessary layers*<br>\n",
    "*Raw should be whole, positive, ~10<sup>3*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if adata.raw:\n",
    "    print('raw min = ' + str(adata.raw.X.min()))\n",
    "    print('raw max = ' + str(adata.raw.X.max()))\n",
    "    non_integer = np.any(~np.equal(np.mod(adata.raw.X.data, 1), 0))\n",
    "else:\n",
    "    non_integer = np.any(~np.equal(np.mod(adata.X.data, 1), 0))\n",
    "\n",
    "if non_integer == False:\n",
    "    print('raw is all integers')\n",
    "else:\n",
    "    print('ERROR: raw contains non-integer values')\n",
    "\n",
    "print('X min = ' + str(adata.X.min()))\n",
    "print('X max = ' + str(adata.X.max()))\n",
    "\n",
    "for l in adata.layers:\n",
    "    print(f'layers[{l}] min = ' + str(adata.layers[l].min()))\n",
    "    print(f'layers[{l}] max = ' + str(adata.layers[l].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample:** delete a layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata.layers['other_raw']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# obsm\n",
    "**Confirm at least one set of embeddings is present**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obsm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**View embeddings to identify which matches paper figures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.set_figure_params(dpi=100)\n",
    "for e in adata.obsm:\n",
    "    sc.pl.embedding(adata, basis=e, color='Celltypes_colors', legend_loc='on data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check that the default_embedding value, if defined, is in obsm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'default_embedding' in adata.uns:\n",
    "    de = adata.uns['default_embedding']\n",
    "    if de not in adata.obsm_keys():\n",
    "        print('ERROR:' + de + ' not in ' + ','.join(adata.obsm_keys()))\n",
    "    else:\n",
    "        print(de + ' is in ' + ','.join(adata.obsm_keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample:** update uns.default_embedding\\\n",
    "Ideally, the default_embedding matches the figures in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns['default_embedding'] = 'X_umap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# uns\n",
    "**Check for uns schema fields**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uns_schema =['schema_version','title']\n",
    "for p in uns_schema:\n",
    "    print(p + ': ' + adata.uns.get(p,'MISSING'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample:** define uns.schema_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns['schema_version'] = '3.0.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns['title'] = 'hello'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Browse all of uns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample:** remove deprecated schema field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata.uns['X_normalization']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *_colors\n",
    "**scanpy & cellxgene allow for specification of cluster colors when coloring by specific obs fields**<br>\n",
    "**A list of color codes is specified in `uns.PROP_colors` where `PROP` is an obs field**<br>\n",
    "**The number of color codes in `uns.PROP_colors` must be at least as long as the number of unique values in `obs.PROP`**<br>\n",
    "<br>\n",
    "**Check for _colors fields & ensure each matches a categorical obs field**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numb_types = ['int_', 'int8', 'int16', 'int32', 'int64', 'uint8', 'uint16', 'uint32', 'uint64','float_', 'float16', 'float32', 'float64']\n",
    "\n",
    "for k in adata.uns.keys():\n",
    "    if k.endswith('_colors'):\n",
    "        colors = len(adata.uns[k])\n",
    "        obs_field = k[:-(len('_colors'))]\n",
    "\n",
    "        if obs_field.endswith('_ontology_term_id'):\n",
    "            label_field = obs_field[:-17]\n",
    "            print(f'WARNING: consider copying uns.{k} to uns.{label_field}_colors so palette transfers to CxG viz')\n",
    "\n",
    "        if obs_field in portal_obs_fields:\n",
    "            obs_field += '_ontology_term_id'\n",
    "        if obs_field not in adata.obs.keys():\n",
    "            print(f'WARNING: {obs_field} not found in obs, consider DELETING or RENAMING uns.{k}')\n",
    "        else:\n",
    "            values = len(adata.obs[obs_field].unique())\n",
    "            if colors < values:\n",
    "                print(f'ERROR: uns.{k} has only {str(colors)} colors but obs.{obs_field} has {str(values)} values')\n",
    "            if adata.obs.dtypes[obs_field].name in numb_types:\n",
    "                print(f'ERROR: uns.{k} is associated with non-categorical {obs_field}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ensure the portal fields are not used**<br>\n",
    "**Ensure schema fields are present and values are valid & precise**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in full_obs_standards:\n",
    "    print(o)\n",
    "    if o not in adata.obs_keys():\n",
    "        print('NOT IN OBS')\n",
    "    else:\n",
    "        un = adata.obs[o].unique()\n",
    "        if un.dtype == 'category':\n",
    "            print(un.to_list())\n",
    "        else:\n",
    "            print(un.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the obs layer\n",
    "\n",
    "First we extract the obs layer from the h5ad file that has been provided to us. Then we extract out the obs layer as a csv file. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_obs = adata.obs\n",
    "a_obs.to_csv(\"a_obs_layer.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_obs = adata.raw.obs\n",
    "r_obs.to_csv(\"r_obs_layer.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the excel spreadsheet from the INGEST data submission, and navigate to the sequence_file page.\n",
    "Select the cell_suspension.biomaterial_core.biomaterial_id, cell_suspension.uuid, and library_preparation_protocol.protocol_core.protocol_id and filter for duplicates on those keys. This results in a unique set of cell_suspensions with their related data. \n",
    "\n",
    "See script here: https://github.com/ebi-ait/ingest-cellxgene-submitter#create-obs-layer-from-multiple-cell-suspension-uuids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The manual work here is  matching up unique HCA cell_suspensions and metadata with the  unique samples in the provided-h5ad file. We then generate a final obs_layer.csv which combines HCA metadata with the provided metadata from the contributor in matching rows. There is an opportunity for future automation here for scripts to perform the matching and to provide cell-type ontology terms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a list of fields which should be in the final obs_layer.csv see (https://github.com/chanzuckerberg/single-cell-curation/blob/main/schema/2.0.0/schema.md#obs-cell-metadata)\n",
    "- DCP_Cell_suspension_uuid\n",
    "- DCP_Cell_suspension_ID\n",
    "- assay_ontology_term_id\n",
    "- cell_type_ontology_term_id\n",
    "- development_stage_ontology_term_id\n",
    "- disease_ontology_term_id\n",
    "- self_reported_ethnicity_ontology_term_id\n",
    "- is_primary_data\n",
    "- organism_ontology_term_id\n",
    "- sex_ontology_term_id\n",
    "- tissue_ontology_term_id\n",
    "- donor_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also some manual work here to select cell-type ontology terms from the free text cell-type provided by the contributors. There is an opportunity for future automation here to get scripts / work with other experts in ontology to do this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the final combined obs_layer, then save it as \"obs_layer.csv\" and save it as a dobs object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dobs = pd.read_csv(\"a_obs_layer.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in full_obs_standards:\n",
    "    print(o)\n",
    "    if o not in dobs.keys():\n",
    "        print('NOT IN OBS')\n",
    "    else:\n",
    "        un = dobs[o].unique()\n",
    "        if un.dtype == 'category':\n",
    "            print(un.to_list())\n",
    "        else:\n",
    "            print(un.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs = dobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check here for redundant fields in the obs layer (e.g. tissue_label, donor_ext). Assay_ontology_term_id should be '10x v2 5' sequencing' as opposed to '10x TCR'.\n",
    "Development_stage and tissue should be made specific (e.g. 35-year old human stage).\n",
    "Unannotated cells use CL:0000003 (native cell).\n",
    "Check that certain fields in the obs layer should not be continuous / numerical, but should be categorical or string. Use the cells below to fix this if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample:** set the index to the \"barcodes\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dobs = dobs.set_index(\"Unnamed: 0\", inplace = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample:** drop \"author_tissue\" and \"donor_ext\" columns from obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs = adata.obs.drop(['Unnamed: 18','author_tissue','tissue_label','donor_ext'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample:** set specific obs datatypes to category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs = adata.obs.astype({'batch': 'category','cluster':'category'}, copy = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ensure the portal fields are not used**<br>\n",
    "**Ensure schema fields are present and values are valid & precise**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in full_obs_standards:\n",
    "    print(o)\n",
    "    if o not in adata.obs_keys():\n",
    "        print('NOT IN OBS')\n",
    "    else:\n",
    "        un = adata.obs[o].unique()\n",
    "        if un.dtype == 'category':\n",
    "            print(un.to_list())\n",
    "        else:\n",
    "            print(un.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10x barcode checker\n",
    "**Checks a random 1k barcodes against 10x barcode lists**<br>\n",
    "*Can help confirm 3' v2 vs v3 vs multiome*<br>\n",
    "*5' v1 and v2 kits use the same barcode list as 3' v2*<br>\n",
    "*Assumes the barcode is in the index. Suffixes/prefixes are OK*<br>\n",
    "<br>\n",
    "**Define the function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from random import randint\n",
    "\n",
    "\n",
    "def TENx_barcode_checker(df):\n",
    "    num_to_check = 1000\n",
    "\n",
    "    v2_file = '/Users/wteh/Documents/Wrangling/Cellxgene/Notebooks/737K-august-2016.txt'\n",
    "    v3_file = '/Users/wteh/Documents/Wrangling/Cellxgene/Notebooks/3M-february-2018.txt'\n",
    "    multiome_file = '/Users/wteh/Documents/Wrangling/Cellxgene/Notebooks/737K-arc-v1.txt'\n",
    "\n",
    "    v2_list = [line.strip() for line in open(v2_file, 'r')]\n",
    "    v3_list = [line.strip() for line in open(v3_file, 'r')]\n",
    "    multiome_list = [line.strip() for line in open(multiome_file, 'r')]\n",
    "\n",
    "    cellcount = df.index.shape[0]\n",
    "    barcode_pattern = '[ACTG]{16}'\n",
    "    barcode_results = ''\n",
    "    if re.search(barcode_pattern, df.index[5]):\n",
    "        cellcount\n",
    "        random_indices = [randint(0, cellcount - 1) for p in range(0, num_to_check)]\n",
    "        barcodes = {'3pv2_5pv1_5pv2': 0,'3pv3': 0,'multiome': 0,'multiple': 0,'none': 0}\n",
    "        for i in random_indices:\n",
    "            if re.search(barcode_pattern, df.index[i]):\n",
    "                barcode = re.search(barcode_pattern, df.index[i]).group(0)\n",
    "                if barcode in v2_list:\n",
    "                    if barcode in multiome_list:\n",
    "                        barcodes['multiple'] += 1\n",
    "                    elif barcode in v3_list:\n",
    "                        barcodes['multiple'] += 1\n",
    "                    else:\n",
    "                        barcodes['3pv2_5pv1_5pv2'] += 1\n",
    "                elif barcode in multiome_list:\n",
    "                    if barcode in v3_list:\n",
    "                        barcodes['multiple'] += 1\n",
    "                    else:\n",
    "                        barcodes['multiome'] += 1\n",
    "                elif barcode in v3_list:\n",
    "                    barcodes['3pv3'] += 1\n",
    "                else:\n",
    "                    barcodes['none'] += 1\n",
    "        return barcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check 1k barcodes across the whole obs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = TENx_barcode_checker(adata.obs)\n",
    "if not results:\n",
    "    print('no barcodes checked')\n",
    "pd.DataFrame([results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additionally, can check 1k barcodes from multiple subsets of obs**<br>\n",
    "*Define `prop` and 1k barcodes will be checked for each unique value in `obs.prop`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop = 'assay_ontology_term_id'\n",
    "\n",
    "results = []\n",
    "for a in adata.obs[prop].value_counts().keys():\n",
    "    print(a)\n",
    "    r = TENx_barcode_checker(adata.obs[adata.obs[prop] == a])\n",
    "    if r:\n",
    "        r[prop] = a\n",
    "        results.append(r)\n",
    "    else:\n",
    "        print('no barcodes checked')\n",
    "pd.DataFrame(results).set_index(prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample:** set a column with all the same values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['is_primary_data'] = True\n",
    "adata.obs['suspension_type'] = 'nucleus'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample:** change column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_me = {\n",
    "    'cell_type': 'author_cell_type',\n",
    "    'ethnicity_ontology_id': 'self_reported_ethnicity_ontology_term_id',\n",
    "    'disease_ontology_id': 'disease_ontology_term_id'\n",
    "}\n",
    "\n",
    "adata.obs.rename(columns=rename_me, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample:** fill null values of a specific column with a specified value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['sex_ontology_term_id'].cat.add_categories('unknown', inplace=True)\n",
    "adata.obs.fillna({'sex_ontology_term_id': 'unknown'}, inplace=True)\n",
    "adata.obs['sex_ontology_term_id'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample:** adjust the values in a specific column in a standard way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_typo(x):\n",
    "    return x.replace('_',':')\n",
    "\n",
    "\n",
    "adata.obs['development_stage_ontology_term_id'] = adata.obs['development_stage_ontology_term_id'].apply(fix_typo)\n",
    "adata.obs['development_stage_ontology_term_id'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample:** replace specified values in specified columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_me = {\n",
    "    'organism_ontology_term_id':{'human':'NCBITaxon:9606', 'mouse': 'NCBITaxon:10090'},\n",
    "    'assay_ontology_term_id': {'EFO:0030003': 'EFO:0009899'}\n",
    "}\n",
    "\n",
    "adata.obs.replace(replace_me,inplace=True)\n",
    "adata.obs[['organism_ontology_term_id','assay_ontology_term_id']].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample:** add a new column with values based on values in an existing column - with DataFrame<br>\n",
    "**Step 1:** get the values to map from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in adata.obs['author_cell_type'].unique():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample:** add a new column with values based on values in an existing column<br>\n",
    "**Step 2:** set up a dataframe with the mapping\n",
    "**Option A:** from a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map in values based on another field - step 2: set up a dataframe with the mapping\n",
    "#option A: from dict\n",
    "celltypes = {\n",
    "    'Myeloid': 'CL:0001082',\n",
    "    'Endothelial': 'CL:0010008',\n",
    "    'Fibroblast': 'CL:0002548',\n",
    "    'Cardiomyocyte': 'CL:0000513',\n",
    "    'Pericyte': 'CL:0000669',\n",
    "    'Lymphoid': 'CL:0000838',\n",
    "    'Cycling cells': 'CL:0000003',\n",
    "    'vSMCs': 'CL:0000514',\n",
    "    'Neuronal': 'CL:0000006'\n",
    "}\n",
    "\n",
    "ct_df = pd.DataFrame.from_dict(celltypes,orient='index',columns=['cell_type_ontology_term_id']).reset_index().rename(columns={'index':'author_cell_type'})\n",
    "ct_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample:** add a new column with values based on values in an existing column<br>\n",
    "**Step 2:** set up a dataframe with the mapping<br>\n",
    "**Option B:** from a Google Sheet<br>\n",
    "*Google Sheet permissions must be Anyone with Link is a Viewer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_id = '15oG8v5BS6HMPqCehYQcujMZUq9PgQNpo8osKhO7yA5o'\n",
    "tab_name = 'Sheet1'\n",
    "url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={tab_name}'\n",
    "ct_df = pd.read_csv(url)\n",
    "ct_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample:** add a new column with values based on values in an existing column<br>\n",
    "**Step 3:** merge the dataframe into obs<br>\n",
    "*`how='left'` is critical to ensure obs order is retained*<br>\n",
    "*`set_index` is critical to ensure the index is retained*<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs = adata.obs.merge(ct_df, on='author_cell_type',how='left').set_index(adata.obs.index)\n",
    "adata.obs[['author_cell_type','cell_type_ontology_term_id']].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample:** add a new column with values based on values in an existing column - with Dictionary<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['sample'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donor_map = {\n",
    "    'KL001': 'P21',\n",
    "    'KL002': 'P22',\n",
    "    'KL003': 'P23'\n",
    "}\n",
    "\n",
    "adata.obs['donor_id'] = adata.obs['sample'].map(donor_map)\n",
    "adata.obs[['donor_id','sample']].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Look for general obs field issues and collect obs information to check for redundant information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_fields = []\n",
    "gradient_fields = []\n",
    "uber_dict = {}\n",
    "for o in adata.obs.keys():\n",
    "    vc_dict = adata.obs[o].value_counts(dropna=False).to_dict()\n",
    "    counts = '_'.join([str(c) for c in vc_dict.values()])\n",
    "    count_len = len(vc_dict.keys())\n",
    "    values = [str(i) for i in vc_dict.keys()]\n",
    "\n",
    "    if o.startswith(' ') or o.endswith(' ') or '  ' in o:\n",
    "        print('leading/trailing whitespace:' + o)\n",
    "\n",
    "    if o not in full_obs_standards and ' '.join(o.split()).lower() in full_obs_standards:\n",
    "        print('schema conflict:' + o)\n",
    "\n",
    "    if count_len == 1:\n",
    "        lone_v = str(list(vc_dict.keys())[0])\n",
    "        if o not in full_obs_standards:\n",
    "            print('all same value:' + o + ',' + lone_v)\n",
    "\n",
    "    numb_types = ['int_', 'int8', 'int16', 'int32', 'int64', 'uint8', 'uint16', 'uint32', 'uint64','float_', 'float16', 'float32', 'float64']\n",
    "    if adata.obs.dtypes[o].name in numb_types:\n",
    "        gradient_fields.append(o)\n",
    "    #check for long categories as they will not be enabled for coloring\n",
    "    elif count_len > 200:\n",
    "        long_fields.append(o)\n",
    "\n",
    "    #report value_counts to later look for redundancy\n",
    "    metadata = {\n",
    "        'values': values,\n",
    "        'property': o\n",
    "    }\n",
    "    if counts in uber_dict:\n",
    "        uber_dict[counts].append(metadata)\n",
    "    else:\n",
    "        uber_dict[counts] = [metadata]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comb value_counts to report possible redundancy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in uber_dict.items():\n",
    "    if '_' in k and not k.startswith('1_1'):\n",
    "        props = [e['property'] for e in v]\n",
    "        if len(v) > 1 and not all(elem in full_obs_standards for elem in props):\n",
    "            print('cells breakdown: ' + k)\n",
    "            for e in v:\n",
    "                print(e['property'])\n",
    "                #print(e['values'])\n",
    "            print('----------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Investigate any fields that may be redundant**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[['sample','patient','age','development_stage_ontology_term_id']].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check for fields that aren't appropriate as gradient (e.g. cluster number)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update a gradient field to categorical, if needed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['cluster_id'] = adata.obs['cluster_id'].map(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**List any categorical fields with more than 200 categories as they may not be useful in the visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**List any obs columns to remove and remove them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_remove = [\n",
    "    'tissue',\n",
    "    'organism',\n",
    "    'self_reported_ethnicity',\n",
    "    'assay',\n",
    "    'disease',\n",
    "    'sex',\n",
    "    'cell_type'\n",
    "]\n",
    "\n",
    "obs_remove = [o for o in obs_remove if o in adata.obs.columns]\n",
    "adata.obs.drop(columns=obs_remove, inplace=True)\n",
    "if obs_remove:\n",
    "    print('removed: ' + ','.join(obs_remove))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ensure the portal fields are not used**<br>\n",
    "**Ensure schema fields are present and values are valid & precise**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in full_obs_standards:\n",
    "    print(o)\n",
    "    if o not in adata.obs_keys():\n",
    "        print('NOT IN OBS')\n",
    "    else:\n",
    "        un = adata.obs[o].unique()\n",
    "        if un.dtype == 'category':\n",
    "            print(un.to_list())\n",
    "        else:\n",
    "            print(un.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# var\n",
    "**Check for Ensembl IDs, redundant fields, etc.**<br>\n",
    "**Check for schema fields**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Gene Symbols to ENSEMBL IDs\n",
    "**Skip this section if there are already ENSEMBL IDs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.raw.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_adata = ad.AnnData(adata.raw.X, var=adata.raw.var, obs=adata.obs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set ENSEMBL IDs as barcodes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var = adata.var.set_index(\"gene_ids-1\", inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_adata.var = raw_adata.var.set_index(\"gene_ids-1\", inplace = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If CellRanger may have been used for alignment, check against the default CellRanger references for matches in order to inform symbol-to-ID mapping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CR_12 = '/Users/wteh/Documents/Wrangling/Cellxgene/Notebooks/refdata-cellranger-GRCh38-1_2_0_genes_gtf.tsv'\n",
    "CR_30 = '/Users/wteh/Documents/Wrangling/Cellxgene/Notebooks/refdata-cellranger-GRCh38-3_0_0_genes_gtf.tsv'\n",
    "CR_2020 = '/Users/wteh/Documents/Wrangling/Cellxgene/Notebooks/refdata-gex-GRCh38-2020-A_genes_gtf.tsv'\n",
    "CR_hg19 = '/Users/wteh/Documents/Wrangling/Cellxgene/Notebooks/refdata-cellranger-hg19-1_2_0_genes_gtf.tsv'\n",
    "for v in [CR_12,CR_30,CR_2020,CR_hg19]:\n",
    "    map_df = pd.read_csv(v, sep='\\t')\n",
    "    print(v)\n",
    "    print(adata.var.merge(map_df,left_index=True,right_on='gene_symbols',how='inner').shape[0])\n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fill in the mapping file to use to map symbols to Ensembl IDs**<br>\n",
    "*Expecting a .tsv with columns `gene_symbols` & `gene_ids`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_mapping_file = CR_12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**View what features are not mapped in this**<br>\n",
    "*Check for typos or other alterations to the symbols that can be fixed*<br>\n",
    "*Common to see many ending in `.1` or `-1` resulting from duplicated symbols in the reference*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shows list of gene features that are not properly mapped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_map_df = pd.read_csv(var_mapping_file, sep='\\t')\n",
    "adata.var[adata.var.index.isin(var_map_df['gene_symbols']) != True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Filtered out genes from raw to normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Skip this section if there is the identical number of genes in raw and normalized (if cell below = True)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If any genes genes have been filtered out when the authors processed the raw matrix, they will not available in the annotated matrix. We need to add them to the processed matrix. We checked this by inspecting the matrices, but can be checked again by running the following cell:\n",
    "- Check that both dataframes have the same number of rows. If they are different, the authors filtered out some genes from the PROCESSED, and we will need to add them in. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvar = pd.DataFrame(data=adata.var)\n",
    "rvar = pd.DataFrame(data=raw_adata.var)\n",
    "dvar.shape[0] == rvar.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If some of the features have been filtered out of the processed matrices, we have to add the filtered-out genes at the end of the matrices. For that, we are going to first fill in the *feature_is_filtered* column at the rvar dataframe. We can then create a new dataframe dropping all the non filtered gene, and add this dataframe with the filtered genes at the end of dvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_add = [x for x in rvar.index.to_list() if x not in adata.var.index.to_list()]\n",
    "all_genes = adata.var.index.to_list()\n",
    "all_genes.extend(genes_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_var = pd.DataFrame(index=all_genes)\n",
    "new_var = pd.merge(new_var, rvar, left_index=True, right_index=True, how='left')\n",
    "new_var['feature_is_filtered'] = False\n",
    "new_var.loc[genes_add, 'feature_is_filtered'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Also editing the X layer to add filtered out genes from raw to normalized matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dExprs = pd.DataFrame(data=adata.X)\n",
    "dExprs = dExprs.set_axis(dvar.index.to_list(), axis=1, inplace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dExprs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dExprsgenesToAdd = new_var.loc[new_var['feature_is_filtered'] == True]\n",
    "dExprs = dExprs.reindex(columns=[*dExprs.columns.tolist(), *dExprsgenesToAdd.index.to_list()], fill_value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dExprs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Similar checks for raw.var, if present**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rExprs = pd.DataFrame(data=raw_adata.X.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rExprs = rExprs.set_axis(rvar.index.to_list(), axis = 1, inplace=False)\n",
    "rExprs = rExprs.reindex(columns = dExprs.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rvar = rvar.reindex(index=dExprs.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rExprs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dExprs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out not-approved genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the list of approved IDs to filter on**<br>\n",
    "*For the initial run, download the 4 genes_ csv files from https://github.com/chanzuckerberg/single-cell-curation/tree/main/cellxgene_schema_cli/cellxgene_schema/ontology_files*<br>\n",
    "*After that, if the `genes_approved.csv` is available locally, then the 4 genes_ files won't be necessary*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_files = [\n",
    "    'genes_ercc.csv',\n",
    "    'genes_homo_sapiens.csv',\n",
    "    'genes_mus_musculus.csv',\n",
    "    'genes_sars_cov_2.csv'\n",
    "]\n",
    "\n",
    "if not os.path.exists('genes_approved.csv'):\n",
    "    ids = pd.DataFrame()\n",
    "    for f in ref_files:\n",
    "        df = pd.read_csv(f, names=['feature_id','symb','num','length'],dtype='str',index_col=False)\n",
    "        ids = ids.append(df)\n",
    "        os.remove(f)\n",
    "    ids.to_csv('genes_approved.csv', index=False)\n",
    "\n",
    "approved = pd.read_csv('genes_approved.csv',dtype='str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample:** set columns with all the same values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var['feature_is_filtered'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove any fields (typically symbols as the portal will add those)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_remove = [\n",
    "    'gene_symbols'\n",
    "]\n",
    "\n",
    "adata.var.drop(columns=var_remove, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Map the Ensembl IDs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var = adata.var.merge(var_map_df,left_index=True,right_on='gene_symbols',how='left').set_index(adata.var.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter out genes that don't appear in the approved annotation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_to_keep = adata.var.index.tolist()\n",
    "var_in_approved = adata.var.index[adata.var['gene_ids'].isin(approved['feature_id'])].tolist()\n",
    "var_to_keep = [e for e in var_to_keep if e in var_in_approved]\n",
    "adata = adata[:, var_to_keep]\n",
    "adata.var.set_index('gene_ids',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Repeat much of the same steps for the `raw.var`, if it exists**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rExprs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rvar.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_var_remove = [\n",
    "    'gene_ids-0'\n",
    "]\n",
    "rvar.drop(columns=raw_var_remove, inplace=True)\n",
    "\n",
    "raw_adata = ad.AnnData(rExprs, var=rvar, obs=adata.obs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_adata.var = raw_adata.var.merge(var_map_df,left_index=True,right_on='gene_symbols',how='left').set_index(raw_adata.var.index)\n",
    "\n",
    "raw_adata = raw_adata[:, var_to_keep]\n",
    "raw_adata.var.set_index('gene_ids',inplace=True)\n",
    "adata.raw = raw_adata\n",
    "adata.raw.var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate\n",
    "**Determine the embedding by which to plot**\\\n",
    "May need to overwrite if the first obsm is not informative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_embedding = adata.uns.get('default_embedding')\n",
    "umap_embedding = None\n",
    "tsne_embdding = None\n",
    "for k in adata.obsm_keys():\n",
    "    if 'umap' in k.lower():\n",
    "        umap_embedding = k\n",
    "    elif 'tsne' in k.lower():\n",
    "        tsne_embdding = k\n",
    "if not default_embedding:\n",
    "    if umap_embedding:\n",
    "        default_embedding = umap_embedding\n",
    "    elif tsne_embdding:\n",
    "        default_embedding = tsne_embdding\n",
    "    else:\n",
    "        default_embedding = adata.obsm_keys()[0]\n",
    "default_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the cells to ensure they cluster by cell type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.set_figure_params(dpi=150)\n",
    "sc.pl.embedding(adata, basis=default_embedding, color=['cell_type_ontology_term_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The above plot will set a color palette in uns, so remove that**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata.uns['cell_type_ontology_term_id_colors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot by multiple genes using the normalized counts**<br>\n",
    "*It is best to get a list of genes relevant to the specific data from the contributor/publication*"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "symbol_list = [\n",
    "    'SKAP1', #lymphoid\n",
    "    'RIPOR2', #lymphoid\n",
    "    'THEMIS', #lymphoid\n",
    "    'RBM47', #myeloid\n",
    "    'TBXAS1', #myeloid\n",
    "    'CD163', #myeloid\n",
    "    'VWF', #endothelial\n",
    "    'ANO2', #endothelial\n",
    "    'EGFL7', #endothelial\n",
    "    'BICC1', #fibroblast\n",
    "    'MEG3', #fibroblast\n",
    "    'COL6A3', #fibroblast\n",
    "    'RMB20', #cardiomyocyte\n",
    "    'ACTN2', #cardiomyocyte\n",
    "    'LDB3' #cardiomyocyte\n",
    "]\n",
    "\n",
    "ensg_list = []\n",
    "for s in symbol_list:\n",
    "    if s in approved['symb'].tolist():\n",
    "        ensg_id = approved.loc[approved['symb'] == s, 'feature_id'].iloc[0]\n",
    "        if ensg_id in adata.var.index:\n",
    "            ensg_list.append(ensg_id)\n",
    "        else:\n",
    "            print(f'{s}/{ensg_id} not found in var')\n",
    "    else:\n",
    "        print(f'{s} not found in gene file')\n",
    "\n",
    "ensg_list"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sc.pl.embedding(adata, basis=default_embedding, color=ensg_list, use_raw=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare with the same genes using the raw counts to confirm they are correlated**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sc.pl.embedding(adata, basis=default_embedding, color=ensg_list, use_raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additionally, you could compare dotplots of those genes in each cell population**<br>\n",
    "*This will scale all genes based on the max range of any gene so 1 gene with high values may make others difficult to distinguish*"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sc.pl.dotplot(adata, ensg_list, 'cell_type_ontology_term_id', use_raw=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sc.pl.dotplot(adata, ensg_list, 'cell_type_ontology_term_id', use_raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write the file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_one = file + '_revised.h5ad'\n",
    "adata.write(filename=new_one, compression='gzip')\n",
    "new_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the CELLxGENE validator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_process = subprocess.run(['cellxgene-schema', 'validate', new_one], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "for line in validate_process.stdout.decode('utf-8').split('\\n'):\n",
    "    print(line)\n",
    "for line in validate_process.stderr.decode('utf-8').split('\\n'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellxgene",
   "language": "python",
   "name": "cellxgene"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
